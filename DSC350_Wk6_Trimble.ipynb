{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Title: DSC350 Week 6 Exercises  \n",
    "Author: Stefanie Molin  \n",
    "Date: 04 October 2024  \n",
    "Modified By: Caleb Trimble \n",
    "Description: This program focuses on tailor dataframes based on specific values, creating bins for set values, creating crosstabs and pivot tables, conducting calculations on data, and merging dataframes. \n",
    "Codes in this program have been adapted from Hands-On Data Analysis with Pandas - Second Edition (Molin S., 2021)"
   ],
   "id": "11b12823b7785da0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-05T04:15:18.183635Z",
     "start_time": "2024-10-05T04:15:18.165859Z"
    }
   },
   "source": [
    "# Problem 1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('earthquakes.csv')\n",
    "df.head()\n",
    "\n",
    "# Creates a DataFrame that shows the results for specific location, magnitude, and magnitude type.\n",
    "japan_quakes = df[(df['parsed_place'] == \"Japan\") & (df['mag'] > 4.9) & (df['magType'] == \"mb\")]\n",
    "print(japan_quakes)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      mag magType           time                       place  tsunami  \\\n",
      "2576  5.4      mb  1538697528010  37km E of Tomakomai, Japan        0   \n",
      "\n",
      "     parsed_place  \n",
      "2576        Japan  \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T04:20:11.337714Z",
     "start_time": "2024-10-05T04:20:11.315868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Problem 2\n",
    "\n",
    "df = pd.read_csv('earthquakes.csv')\n",
    "# Creates a DataFrame specifically for the magnitude type \"ml\".\n",
    "ml_spec = df[(df['magType'] == \"ml\")] \n",
    "df.head()\n",
    "# Creates a new DataFrame featuring 9 bins, with each bin representing a specific magnitude.\n",
    "ml_binned = pd.cut(ml_spec.mag, bins=9, labels=['1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "# Counts the number of values in each of the 5 bins. \n",
    "ml_binned.value_counts()"
   ],
   "id": "70280fb001559f51",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mag\n",
       "4    2316\n",
       "5    1651\n",
       "3    1515\n",
       "2     582\n",
       "6     496\n",
       "7     142\n",
       "1      80\n",
       "8      19\n",
       "9       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T02:20:46.012378Z",
     "start_time": "2024-10-04T02:20:45.964239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Problem 3\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('faang.csv')\n",
    "# Sets the format for the date column to the datetime data type instead of an object.\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "# Sets the DataFrame index to the date column.\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Creates a new DataFrame that resamples the data to a 1-month time period and groups the data by the ticker column.\n",
    "df_resample = df.groupby('ticker').resample('1M').agg({\n",
    "# Calculates various statistics using numpy functions.\n",
    "    'open': np.mean,  \n",
    "    'high': np.max,\n",
    "    'low': np.min,\n",
    "    'close': np.mean,\n",
    "    'volume': np.sum,\n",
    "})\n",
    "print(df_resample.head())\n"
   ],
   "id": "b091b542465b757c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        open       high        low      close        volume\n",
      "ticker date                                                                \n",
      "AAPL   2018-01-31  43.505357  45.025002  41.174999  43.501309  2.638718e+09\n",
      "       2018-02-28  41.819079  45.154999  37.560001  41.909737  3.711577e+09\n",
      "       2018-03-31  43.761786  45.875000  41.235001  43.624048  2.854911e+09\n",
      "       2018-04-30  42.441310  44.735001  40.157501  42.458572  2.664617e+09\n",
      "       2018-05-31  46.239091  47.592499  41.317501  46.384205  2.483905e+09\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T04:22:40.554575Z",
     "start_time": "2024-10-05T04:22:40.513137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Problem 4\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tsunamis = pd.read_csv('earthquakes.csv')\n",
    "\n",
    "# Calculates the maximum magnitude for each combination of tsunami and magType\n",
    "max_mag = tsunamis.groupby(['tsunami', 'magType'])['mag'].max().reset_index()\n",
    "\n",
    "# Creates the crosstab\n",
    "crosstab = pd.crosstab(\n",
    "    index=tsunamis['tsunami'],\n",
    "    columns=tsunamis['magType'],\n",
    "    values=tsunamis['mag'],\n",
    "    aggfunc='max',\n",
    "    margins=True,\n",
    "    margins_name='Total Observations'\n",
    ")\n",
    "\n",
    "print(max_mag.head())\n",
    "print(crosstab.head())\n"
   ],
   "id": "ff77d3aa678f41f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tsunami magType   mag\n",
      "0        0      mb  5.60\n",
      "1        0   mb_lg  3.50\n",
      "2        0      md  4.11\n",
      "3        0      mh  1.10\n",
      "4        0      ml  4.20\n",
      "magType              mb  mb_lg    md   mh   ml  ms_20    mw  mwb  mwr  mww  \\\n",
      "tsunami                                                                      \n",
      "0                   5.6    3.5  4.11  1.1  4.2    NaN  3.83  5.8  4.8  6.0   \n",
      "1                   6.1    NaN   NaN  NaN  5.1    5.7  4.41  NaN  NaN  7.5   \n",
      "Total Observations  6.1    3.5  4.11  1.1  5.1    5.7  4.41  5.8  4.8  7.5   \n",
      "\n",
      "magType             Total Observations  \n",
      "tsunami                                 \n",
      "0                                  6.0  \n",
      "1                                  7.5  \n",
      "Total Observations                 7.5  \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T02:49:25.146275Z",
     "start_time": "2024-10-04T02:49:25.102309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Problem 5\n",
    "# Calculates the rolling 60-day aggregations. \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('faang.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df_resample = df.groupby('ticker').resample('60D').agg({\n",
    "    'open': np.mean,\n",
    "    'high': np.max,\n",
    "    'low': np.min,\n",
    "    'close': np.mean,\n",
    "    'volume': np.sum,\n",
    "})\n",
    "print(df_resample.head())"
   ],
   "id": "48b817ddd7e756d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        open       high        low      close        volume\n",
      "ticker date                                                                \n",
      "AAPL   2018-01-02  42.762143  45.154999  37.560001  42.800357  6.699319e+09\n",
      "       2018-03-03  43.025183  45.875000  40.157501  42.980671  5.384782e+09\n",
      "       2018-05-02  46.820000  48.549999  43.450001  46.867619  4.380126e+09\n",
      "       2018-07-01  50.187857  55.872501  45.855000  50.302619  4.007506e+09\n",
      "       2018-08-30  55.575793  58.367500  53.080002  55.531159  5.759600e+09\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T03:05:25.975824Z",
     "start_time": "2024-10-04T03:05:25.962209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Problem 6\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('faang.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Creates a pivot table using the ticker as the index, OHLCV as the values, and defines the aggregate function.\n",
    "pivot_table = df.pivot_table(\n",
    "    index='ticker',\n",
    "    values=['open', 'high', 'low', 'close', 'volume'],\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "print(pivot_table)\n"
   ],
   "id": "ee50c2fcb80a803f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              close         high          low         open        volume\n",
      "ticker                                                                  \n",
      "AAPL      47.263357    47.748526    46.795877    47.277859  1.360803e+08\n",
      "AMZN    1641.726176  1662.839839  1619.840519  1644.072709  5.648994e+06\n",
      "FB       171.510956   173.613347   169.303148   171.472948  2.765860e+07\n",
      "GOOG    1113.225134  1125.777606  1101.001658  1113.554101  1.741965e+06\n",
      "NFLX     319.290319   325.219322   313.187330   319.620558  1.146962e+07\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T04:34:58.146815Z",
     "start_time": "2024-10-05T04:34:58.118431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Problem 7\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('faang.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Creates the DataFrame for z-scores, and defines the specific index to use (AMZN).\n",
    "q4_AMZN_z_scores = df[(df['ticker'] == \"AMZN\")]\\\n",
    "    .loc['2018-Q4', ['high', 'low', 'open', 'close', 'volume']]\\\n",
    "    .apply(lambda x: x.sub(x.mean()).div(x.std()))\n",
    "# Provides the description of the DataFrame.\n",
    "q4_AMZN_z_scores.describe().T\n"
   ],
   "id": "fd0cfa7a89dde809",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        count          mean  std       min       25%       50%       75%  \\\n",
       "high     63.0 -1.656523e-16  1.0 -2.159820 -0.772677 -0.055727  0.635606   \n",
       "low      63.0 -7.648203e-16  1.0 -2.187566 -0.729262 -0.083067  0.643712   \n",
       "open     63.0 -6.379377e-16  1.0 -2.179582 -0.662691 -0.021091  0.664414   \n",
       "close    63.0  6.696583e-17  1.0 -2.226185 -0.672697 -0.030371  0.696701   \n",
       "volume   63.0  1.599250e-16  1.0 -1.928641 -0.662240 -0.282926  0.480970   \n",
       "\n",
       "             max  \n",
       "high    2.368006  \n",
       "low     2.502113  \n",
       "open    2.337813  \n",
       "close   2.385848  \n",
       "volume  2.926152  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>63.0</td>\n",
       "      <td>-1.656523e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.159820</td>\n",
       "      <td>-0.772677</td>\n",
       "      <td>-0.055727</td>\n",
       "      <td>0.635606</td>\n",
       "      <td>2.368006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>63.0</td>\n",
       "      <td>-7.648203e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.187566</td>\n",
       "      <td>-0.729262</td>\n",
       "      <td>-0.083067</td>\n",
       "      <td>0.643712</td>\n",
       "      <td>2.502113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>63.0</td>\n",
       "      <td>-6.379377e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.179582</td>\n",
       "      <td>-0.662691</td>\n",
       "      <td>-0.021091</td>\n",
       "      <td>0.664414</td>\n",
       "      <td>2.337813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>63.0</td>\n",
       "      <td>6.696583e-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.226185</td>\n",
       "      <td>-0.672697</td>\n",
       "      <td>-0.030371</td>\n",
       "      <td>0.696701</td>\n",
       "      <td>2.385848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.599250e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.928641</td>\n",
       "      <td>-0.662240</td>\n",
       "      <td>-0.282926</td>\n",
       "      <td>0.480970</td>\n",
       "      <td>2.926152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Line 10 - Defines what we want to see. In this case we're looking for quarter 4 of 2018, and we want the z-scores to be reflected for all numerical columns.  \n",
    "Line 11 - Applies the z-score calculation using apply/lambda."
   ],
   "id": "a839aaef3c8ded39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T03:58:30.332840Z",
     "start_time": "2024-10-05T03:58:30.301109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Problem 8\n",
    "import pandas as pd\n",
    "\n",
    "# Creates the initial DataFrame\n",
    "data = {\n",
    "    'ticker': ['FB'] * 3,  # Sets the ticker values as 'FB' for the 3 rows.\n",
    "    'date': ['2018-07-25', '2018-03-19', '2018-03-20'],\n",
    "    'event': ['Disappointing user growth announced after close.', 'Cambridge Analytica story', 'FTC investigation']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "# Sets index to ['date', 'ticker']\n",
    "df.set_index(['date', 'ticker'], inplace=True)\n",
    "\n",
    "faang = pd.read_csv('faang.csv')\n",
    "\n",
    "# Performs the outer merge\n",
    "outer_join = pd.merge(\n",
    "    df.reset_index(), faang.reset_index(), \n",
    "    on=['date', 'ticker'], how='outer', indicator=True\n",
    ")\n",
    "\n",
    "# Concatenates the result\n",
    "result = pd.concat([\n",
    "    outer_join.query(f'_merge == \"{kind}\"').sample(2, random_state=0)\n",
    "    for kind in outer_join._merge.unique()\n",
    "]).sort_index()\n",
    "\n",
    "print(result)\n"
   ],
   "id": "4ef80abc30c412cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date ticker                      event        high         low  \\\n",
      "1   2018-03-19     FB  Cambridge Analytica story  177.169998  170.059998   \n",
      "2   2018-03-20     FB          FTC investigation  170.199997  161.949997   \n",
      "8   2018-01-09     FB                        NaN  188.800003  187.100006   \n",
      "302 2018-03-16   AAPL                        NaN   44.779999   44.404999   \n",
      "\n",
      "           open       close       volume      _merge  \n",
      "1    177.009995  172.559998   88140100.0        both  \n",
      "2    167.470001  168.149994  129851800.0        both  \n",
      "8    188.699997  187.869995   12393100.0  right_only  \n",
      "302   44.662498   44.505001  157618800.0  right_only  \n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T04:03:57.194539Z",
     "start_time": "2024-10-05T04:03:57.177124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Problem 9\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "faang = pd.read_csv('faang.csv')\n",
    "faang['date'] = pd.to_datetime(faang['date'])\n",
    "faang.set_index(['date', 'ticker'], inplace=True)\n",
    "\n",
    "# Groups by ticker and applies the transformation using the transform() method.  \n",
    "faang_transformed = faang.groupby('ticker').transform(lambda x: x / x.iloc[0])\n",
    "\n",
    "print(faang_transformed)\n"
   ],
   "id": "7f53a547f58007c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       high       low      open     close    volume\n",
      "date       ticker                                                  \n",
      "2018-01-02 FB      1.000000  1.000000  1.000000  1.000000  1.000000\n",
      "2018-01-03 FB      1.017623  1.021290  1.023638  1.017914  0.930294\n",
      "2018-01-04 FB      1.025498  1.036891  1.040635  1.016040  0.764708\n",
      "2018-01-05 FB      1.029298  1.041566  1.044518  1.029931  0.747828\n",
      "2018-01-08 FB      1.040313  1.049451  1.053579  1.037813  0.991340\n",
      "...                     ...       ...       ...       ...       ...\n",
      "2018-12-24 GOOG    0.940578  0.928131  0.928993  0.916638  1.284987\n",
      "2018-12-26 GOOG    0.974750  0.940463  0.943406  0.976019  1.917663\n",
      "2018-12-27 GOOG    0.978396  0.953857  0.970248  0.980169  1.704751\n",
      "2018-12-28 GOOG    0.989334  0.988395  1.001221  0.973784  1.143180\n",
      "2018-12-31 GOOG    0.986653  0.979296  1.002499  0.972404  1.206610\n",
      "\n",
      "[1255 rows x 5 columns]\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
